{"cells":[{"cell_type":"code","source":["spark.sparkContext.getConf().getAll()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"305a8be1-3d76-4530-a0de-e10c0de727a1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[4]: [(&#39;spark.files.useFetchCache&#39;, &#39;false&#39;),\n (&#39;spark.databricks.preemption.enabled&#39;, &#39;true&#39;),\n (&#39;spark.driver.tempDirectory&#39;, &#39;/local_disk0/tmp&#39;),\n (&#39;spark.hadoop.fs.adl.impl.disable.cache&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.parquet.block.size.row.check.max&#39;, &#39;10&#39;),\n (&#39;spark.hadoop.fs.s3a.connection.maximum&#39;, &#39;200&#39;),\n (&#39;spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2&#39;, &#39;0&#39;),\n (&#39;spark.executor.extraJavaOptions&#39;,\n  &#39;-Djava.io.tmpdir=/local_disk0/tmp -XX:ReservedCodeCacheSize=512m -XX:+UseCodeCacheFlushing -Djava.security.properties=/databricks/spark/dbconf/java/extra.security -XX:-UseContainerSupport -XX:+PrintFlagsFinal -XX:+PrintGCDateStamps -verbose:gc -XX:+PrintGCDetails -Xss4m -Djava.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni -Djavax.xml.datatype.DatatypeFactory=com.sun.org.apache.xerces.internal.jaxp.datatype.DatatypeFactoryImpl -Djavax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -Djavax.xml.validation.SchemaFactory:http://www.w3.org/2001/XMLSchema=com.sun.org.apache.xerces.internal.jaxp.validation.XMLSchemaFactory -Dorg.xml.sax.driver=com.sun.org.apache.xerces.internal.parsers.SAXParser -Dorg.w3c.dom.DOMImplementationSourceList=com.sun.org.apache.xerces.internal.dom.DOMXSImplementationSourceImpl -Djavax.net.ssl.sessionCacheSize=10000 -Dscala.reflect.runtime.disable.typetag.cache=true -Ddatabricks.serviceName=spark-executor-1&#39;),\n (&#39;spark.hadoop.fs.s3a.fast.upload.active.blocks&#39;, &#39;32&#39;),\n (&#39;spark.shuffle.reduceLocality.enabled&#39;, &#39;false&#39;),\n (&#39;spark.app.id&#39;, &#39;local-1623505984833&#39;),\n (&#39;spark.sql.streaming.checkpointFileManagerClass&#39;,\n  &#39;com.databricks.spark.sql.streaming.DatabricksCheckpointFileManager&#39;),\n (&#39;spark.databricks.clusterUsageTags.driverContainerId&#39;,\n  &#39;0ca6764af05147f896ebcb208e3e2dc3&#39;),\n (&#39;spark.databricks.service.dbutils.repl.backend&#39;,\n  &#39;com.databricks.dbconnect.ReplDBUtils&#39;),\n (&#39;spark.databricks.clusterUsageTags.driverNodeType&#39;, &#39;dev-tier-node&#39;),\n (&#39;spark.hadoop.spark.sql.sources.outputCommitterClass&#39;,\n  &#39;com.databricks.backend.daemon.data.client.MapReduceDirectOutputCommitter&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterName&#39;, &#39;sample&#39;),\n (&#39;spark.hadoop.fs.AbstractFileSystem.gs.impl&#39;,\n  &#39;shaded.databricks.V2_1_4.com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS&#39;),\n (&#39;spark.databricks.clusterUsageTags.instanceBootstrapType&#39;, &#39;ssh&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterId&#39;, &#39;0612-135218-toms290&#39;),\n (&#39;spark.streaming.driver.writeAheadLog.allowBatching&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterSource&#39;, &#39;UI&#39;),\n (&#39;spark.hadoop.hive.server2.transport.mode&#39;, &#39;http&#39;),\n (&#39;spark.hadoop.hive.server2.thrift.http.cookie.auth.enabled&#39;, &#39;false&#39;),\n (&#39;spark.executor.memory&#39;, &#39;8278m&#39;),\n (&#39;spark.databricks.driverNodeTypeId&#39;, &#39;dev-tier-node&#39;),\n (&#39;spark.sql.parquet.compression.codec&#39;, &#39;snappy&#39;),\n (&#39;spark.hadoop.fs.cpfs-adl.impl.disable.cache&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterUsageTags.hailEnabled&#39;, &#39;false&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterLogDeliveryEnabled&#39;, &#39;false&#39;),\n (&#39;spark.databricks.clusterUsageTags.containerType&#39;, &#39;LXC&#39;),\n (&#39;spark.eventLog.enabled&#39;, &#39;false&#39;),\n (&#39;spark.databricks.clusterUsageTags.isIMv2Enabled&#39;, &#39;false&#39;),\n (&#39;spark.databricks.cloudfetch.hasRegionSupport&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.databricks.s3.create.deleteUnnecessaryFakeDirectories&#39;,\n  &#39;false&#39;),\n (&#39;spark.hadoop.fs.wasb.impl&#39;,\n  &#39;shaded.databricks.org.apache.hadoop.fs.azure.NativeAzureFileSystem&#39;),\n (&#39;spark.executor.tempDirectory&#39;, &#39;/local_disk0/tmp&#39;),\n (&#39;spark.databricks.workerNodeTypeId&#39;, &#39;dev-tier-node&#39;),\n (&#39;spark.hadoop.mapred.output.committer.class&#39;,\n  &#39;com.databricks.backend.daemon.data.client.DirectOutputCommitter&#39;),\n (&#39;spark.hadoop.hive.server2.thrift.http.port&#39;, &#39;10000&#39;),\n (&#39;spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version&#39;, &#39;2&#39;),\n (&#39;spark.sql.allowMultipleContexts&#39;, &#39;false&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterEbsVolumeSize&#39;, &#39;0&#39;),\n (&#39;spark.home&#39;, &#39;/databricks/spark&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterTargetWorkers&#39;, &#39;0&#39;),\n (&#39;spark.driver.port&#39;, &#39;40703&#39;),\n (&#39;spark.sql.warehouse.dir&#39;, &#39;/user/hive/warehouse&#39;),\n (&#39;spark.hadoop.hive.server2.idle.operation.timeout&#39;, &#39;7200000&#39;),\n (&#39;spark.task.reaper.enabled&#39;, &#39;true&#39;),\n (&#39;spark.databricks.passthrough.s3a.tokenProviderClassName&#39;,\n  &#39;com.databricks.backend.daemon.driver.aws.AwsCredentialContextTokenProvider&#39;),\n (&#39;spark.storage.memoryFraction&#39;, &#39;0.5&#39;),\n (&#39;spark.databricks.session.share&#39;, &#39;false&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterResourceClass&#39;, &#39;default&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterFirstOnDemand&#39;, &#39;0&#39;),\n (&#39;spark.databricks.clusterUsageTags.driverContainerPrivateIp&#39;,\n  &#39;10.172.211.145&#39;),\n (&#39;spark.driver.maxResultSize&#39;, &#39;4g&#39;),\n (&#39;spark.repl.class.outputDir&#39;,\n  &#39;/local_disk0/tmp/repl/spark-6327425981576752428-cc68f4a7-003b-4500-b6e9-83fe01b8c51c&#39;),\n (&#39;spark.databricks.delta.multiClusterWrites.enabled&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterUsageTags.driverPublicDns&#39;,\n  &#39;ec2-34-219-166-254.us-west-2.compute.amazonaws.com&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterSku&#39;, &#39;STANDARD_SKU&#39;),\n (&#39;spark.worker.cleanup.enabled&#39;, &#39;false&#39;),\n (&#39;spark.sql.legacy.createHiveTableByDefault&#39;, &#39;false&#39;),\n (&#39;spark.hadoop.fs.gs.impl.disable.cache&#39;, &#39;true&#39;),\n (&#39;spark.databricks.workspace.matplotlibInline.enabled&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterUsageTags.sparkVersion&#39;, &#39;8.2.x-scala2.12&#39;),\n (&#39;spark.databricks.clusterUsageTags.enableCredentialPassthrough&#39;, &#39;false&#39;),\n (&#39;spark.databricks.clusterUsageTags.driverInstancePrivateIp&#39;,\n  &#39;10.172.212.157&#39;),\n (&#39;spark.databricks.clusterUsageTags.enableJdbcAutoStart&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterUsageTags.userProvidedRemoteVolumeType&#39;,\n  &#39;ebs_volume_type: GENERAL_PURPOSE_SSD\\n&#39;),\n (&#39;spark.hadoop.fs.wasb.impl.disable.cache&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterEbsVolumeType&#39;,\n  &#39;GENERAL_PURPOSE_SSD&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterLogDestination&#39;, &#39;&#39;),\n (&#39;spark.cleaner.referenceTracking.blocking&#39;, &#39;false&#39;),\n (&#39;spark.hadoop.parquet.page.size.check.estimate&#39;, &#39;false&#39;),\n (&#39;spark.hadoop.spark.driverproxy.customHeadersToProperties&#39;,\n  &#39;X-Databricks-User-Token:spark.databricks.token,X-Databricks-Api-Url:spark.databricks.api.url,X-Databricks-ADLS-Gen1-Token:spark.databricks.adls.gen1.token,X-Databricks-ADLS-Gen2-Token:spark.databricks.adls.gen2.token,X-Databricks-Synapse-Token:spark.databricks.synapse.token,X-Databricks-AWS-Credentials:spark.databricks.aws.creds,X-Databricks-User-Id:spark.databricks.user.id,X-Databricks-User-Name:spark.databricks.user.name&#39;),\n (&#39;spark.databricks.passthrough.s3a.threadPoolExecutor.factory.class&#39;,\n  &#39;com.databricks.backend.daemon.driver.aws.S3APassthroughThreadPoolExecutorFactory&#39;),\n (&#39;spark.repl.class.uri&#39;, &#39;spark://10.172.211.145:40703/classes&#39;),\n (&#39;spark.databricks.clusterUsageTags.isSingleUserCluster&#39;, &#39;false&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterState&#39;, &#39;Pending&#39;),\n (&#39;spark.databricks.tahoe.logStore.azure.class&#39;,\n  &#39;com.databricks.tahoe.store.AzureLogStore&#39;),\n (&#39;spark.databricks.delta.preview.enabled&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.fs.azure.skip.metrics&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.fs.s3.impl&#39;,\n  &#39;shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystem&#39;),\n (&#39;spark.databricks.cloudfetch.requesterClassName&#39;,\n  &#39;com.databricks.spark.sql.cloudfetch.DataDaemonCloudPresignedUrlRequester&#39;),\n (&#39;spark.master&#39;, &#39;local[8]&#39;),\n (&#39;spark.scheduler.mode&#39;, &#39;FAIR&#39;),\n (&#39;spark.sql.sources.default&#39;, &#39;delta&#39;),\n (&#39;spark.databricks.delta.logStore.crossCloud.fatal&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.fs.cpfs-s3n.impl&#39;,\n  &#39;com.databricks.sql.acl.fs.CredentialPassthroughFileSystem&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterWorkers&#39;, &#39;0&#39;),\n (&#39;spark.hadoop.fs.cpfs-adl.impl&#39;,\n  &#39;com.databricks.sql.acl.fs.CredentialPassthroughFileSystem&#39;),\n (&#39;spark.files.fetchFailure.unRegisterOutputOnHost&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.fs.cpfs-abfss.impl&#39;,\n  &#39;com.databricks.sql.acl.fs.CredentialPassthroughFileSystem&#39;),\n (&#39;spark.databricks.sparkContextId&#39;, &#39;6327425981576752428&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterEbsVolumeCount&#39;, &#39;0&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterNumSshKeys&#39;, &#39;0&#39;),\n (&#39;spark.ui.port&#39;, &#39;46321&#39;),\n (&#39;spark.databricks.clusterUsageTags.enableSqlAclsOnly&#39;, &#39;false&#39;),\n (&#39;spark.hadoop.fs.gs.outputstream.upload.chunk.size&#39;, &#39;16777216&#39;),\n (&#39;spark.databricks.tahoe.logStore.aws.class&#39;,\n  &#39;com.databricks.tahoe.store.S3LockBasedLogStore&#39;),\n (&#39;spark.speculation.quantile&#39;, &#39;0.9&#39;),\n (&#39;spark.databricks.clusterUsageTags.privateLinkEnabled&#39;, &#39;false&#39;),\n (&#39;spark.shuffle.manager&#39;, &#39;SORT&#39;),\n (&#39;spark.files.overwrite&#39;, &#39;true&#39;),\n (&#39;spark.driver.host&#39;, &#39;10.172.211.145&#39;),\n (&#39;spark.executor.extraClassPath&#39;,\n  &#39;/databricks/spark/dbconf/log4j/executor:/databricks/spark/dbconf/jets3t/:/databricks/spark/dbconf/hadoop:/databricks/hive/conf:/databricks/jars/----jackson_annotations_shaded--libjackson-annotations.jar:/databricks/jars/----jackson_core_shaded--libjackson-core.jar:/databricks/jars/----jackson_databind_shaded--libjackson-databind.jar:/databricks/jars/----jackson_datatype_joda_shaded--libjackson-datatype-joda.jar:/databricks/jars/----scalapb_090--com.lihaoyi__fastparse_2.12__2.1.3_shaded.jar:/databricks/jars/----scalapb_090--com.lihaoyi__sourcecode_2.12__0.1.7_shaded.jar:/databricks/jars/----scalapb_090--runtime-unshaded-jetty9-hadoop1_2.12_deploy_shaded.jar:/databricks/jars/----workspace_spark_3_1--common--kvstore--kvstore-hive-2.3__hadoop-2.7_2.12_deploy.jar:/databricks/jars/----workspace_spark_3_1--common--network-common--network-common-hive-2.3__hadoop-2.7_2.12_deploy.jar:/databricks/jars/----workspace_spark_3_1--common--network-shuffle--network-shuffle-hive-2.3__hadoop-2.7_2.12_deploy.jar:/databricks/jars/----workspace_spark_3_1--common--sketch--sketch-hive-2.3__hadoop-2.7_2.12_deploy.jar:/databricks/jars/----workspace_spark_3_1--common--tags--tags-hive-2.3__hadoop-2.7_2.12_deploy.jar:/databricks/jars/----workspace_spark_3_1--common--unsafe--unsafe-hive-2.3__hadoop-2.7_2.12_deploy.jar:/databricks/jars/----workspace_spark_3_1--core--core-hive-2.3__hadoop-2.7_2.12_deploy.jar:/databricks/jars/----workspace_spark_3_1--core--libcore_generated_resources.jar:/databricks/jars/----workspace_spark_3_1--core--libcore_resources.jar:/databricks/jars/----workspace_spark_3_1--core--proto-hive-2.3__hadoop-2.7_2.12_deploy.jar:/databricks/jars/----workspace_spark_3_1--graphx--graphx-hive-2.3__hadoop-2.7_2.12_deploy.jar:/databricks/jars/----workspace_spark_3_1--launcher--launcher-hive-2.3__hadoop-2.7_2.12_deploy.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--antlr--antlr--antlr__antlr__2.7.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--amazon-kinesis-client--com.amazonaws__amazon-kinesis-client__1.12.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-autoscaling--com.amazonaws__aws-java-sdk-autoscaling__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-cloudformation--com.amazonaws__aws-java-sdk-cloudformation__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-cloudfront--com.amazonaws__aws-java-sdk-cloudfront__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-cloudhsm--com.amazonaws__aws-java-sdk-cloudhsm__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-cloudsearch--com.amazonaws__aws-java-sdk-cloudsearch__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-cloudtrail--com.amazonaws__aws-java-sdk-cloudtrail__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-cloudwatch--com.amazonaws__aws-java-sdk-cloudwatch__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-cloudwatchmetrics--com.amazonaws__aws-java-sdk-cloudwatchmetrics__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-codedeploy--com.amazonaws__aws-java-sdk-codedeploy__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-cognitoidentity--com.amazonaws__aws-java-sdk-cognitoidentity__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-cognitosync--com.amazonaws__aws-java-sdk-cognitosync__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-config--com.amazonaws__aws-java-sdk-config__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-core--com.amazonaws__aws-java-sdk-core__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-datapipeline--com.amazonaws__aws-java-sdk-datapipeline__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-directconnect--com.amazonaws__aws-java-sdk-directconnect__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-directory--com.amazonaws__aws-java-sdk-directory__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-dynamodb--com.amazonaws__aws-java-sdk-dynamodb__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-ec2--com.amazonaws__aws-java-sdk-ec2__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-ecs--com.amazonaws__aws-java-sdk-ecs__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-efs--com.amazonaws__aws-java-sdk-efs__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-elasticache--com.amazonaws__aws-java-sdk-elasticache__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-elasticbeanstalk--com.amazonaws__aws-java-sdk-elasticbeanstalk__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-elasticloadbalancing--com.amazonaws__aws-java-sdk-elasticloadbalancing__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-elastictranscoder--com.amazonaws__aws-java-sdk-elastictranscoder__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-emr--com.amazonaws__aws-java-sdk-emr__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-glacier--com.amazonaws__aws-java-sdk-glacier__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-iam--com.amazonaws__aws-java-sdk-iam__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-importexport--com.amazonaws__aws-java-sdk-importexport__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-kinesis--com.amazonaws__aws-java-sdk-kinesis__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-kms--com.amazonaws__aws-java-sdk-kms__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-lambda--com.amazonaws__aws-java-sdk-lambda__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-logs--com.amazonaws__aws-java-sdk-logs__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-machinelearning--com.amazonaws__aws-java-sdk-machinelearning__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-opsworks--com.amazonaws__aws-java-sdk-opsworks__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-rds--com.amazonaws__aws-java-sdk-rds__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-redshift--com.amazonaws__aws-java-sdk-redshift__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-route53--com.amazonaws__aws-java-sdk-route53__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-s3--com.amazonaws__aws-java-sdk-s3__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-ses--com.amazonaws__aws-java-sdk-ses__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-simpledb--com.amazonaws__aws-java-sdk-simpledb__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-simpleworkflow--com.amazonaws__aws-java-sdk-simpleworkflow__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-sns--com.amazonaws__aws-java-sdk-sns__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-sqs--com.amazonaws__aws-java-sdk-sqs__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-ssm--com.amazonaws__aws-java-sdk-ssm__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-storagegateway--com.amazonaws__aws-java-sdk-storagegateway__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-sts--com.amazonaws__aws-java-sdk-sts__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-support--com.amazonaws__aws-java-sdk-support__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-swf-libraries--com.amazonaws__aws-java-sdk-swf-libraries__1.11.22.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-workspaces--com.amazonaws__aws-java-sdk-workspaces__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--jmespath-java--com.amazonaws__jmespath-java__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.chuusai--shapeless_2.12--com.chuusai__shapeless_2.12__2.3.3.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.clearspring.analytics--stream--com.clearspring.analytics__stream__2.9.6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.databricks--Rserve--com.databricks__Rserve__1.8-3.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.databricks.scalapb--compilerplugin_2.12--com.databricks.scalapb__compilerplugin_2.12__0.4.15-10.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.databricks.scalapb--scalapb-runtime_2.12--com.databricks.scalapb__scalapb-runtime_2.12__0.4.15-10.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.esotericsoftware--kryo-shaded--com.esotericsoftware__kryo-shaded__4.0.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.esotericsoftware--minlog--com.esotericsoftware__minlog__1.3.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.fasterxml--classmate--com.fasterxml__classmate__1.3.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.fasterxml.jackson.core--jackson-annotations--com.fasterxml.jackson.core__jackson-annotations__2.10.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.fasterxml.jackson.core--jackson-core--com.fasterxml.jackson.core__jackson-core__2.10.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.fasterxml.jackson.core--jackson-databind--com.fasterxml.jackson.core__jackson-databind__2.10.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.fasterxml.jackson.dataformat--jackson-dataformat-cbor--com.fasterxml.jackson.dataformat__jackson-dataformat-cbor__2.10.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.fasterxml.jackson.datatype--jackson-datatype-joda--com.fasterxml.jackson.datatype__jackson-datatype-joda__2.10.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.fasterxml.jackson.module--jackson-module-paranamer--com.fasterxml.jackson.module__jackson-module-paranamer__2.10.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.fasterxml.jackson.module--jackson-module-scala_2.12--com.fasterxml.jackson.module__jackson-module-scala_2.12__2.10.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.ben-manes.caffeine--caffeine--com.github.ben-manes.caffeine__caffeine__2.3.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.fommil--jniloader--com.github.fommil__jniloader__1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.fommil.netlib--core--com.github.fommil.netlib__core__1.1.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.fommil.netlib--native_ref-java--com.github.fommil.netlib__native_ref-java__1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.fommil.netlib--native_ref-java-natives--com.github.fommil.netlib__native_ref-java-natives__1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.fommil.netlib--native_system-java--com.github.fommil.netlib__native_system-java__1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.fommil.netlib--native_system-java-natives--com.github.fommil.netlib__native_system-java-natives__1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.fommil.netlib--netlib-native_ref-linux-x86_64-natives--com.github.fommil.netlib__netlib-native_ref-linux-x86_64-natives__1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.fommil.netlib--netlib-native_system-linux-x86_64-natives--com.github.fommil.netlib__netlib-native_system-linux-x86_64-natives__1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.joshelser--dropwizard-metrics-hadoop-metrics2-reporter--com.github.joshelser__dropwizard-metrics-hadoop-metrics2-reporter__0.1.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.luben--zstd-jni--com.github.luben__zstd-jni__1.4.8-1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.wendykierp--JTransforms--com.github.wendykierp__JTransforms__3.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.google.code.findbugs--jsr305--com.google.code.findbugs__jsr305__3.0.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.google.code.gson--gson--com.google.code.gson__gson__2.2.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.google.flatbuffers--flatbuffers-java--com.google.flatbuffers__flatbuffers-java__1.9.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.google.guava--guava--com.google.guava__guava__15.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.google.protobuf--protobuf-java--com.google.protobuf__protobuf-java__2.6.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.h2database--h2--com.h2database__h2__1.4.195.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.helger--profiler--com.helger__profiler__1.1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.jcraft--jsch--com.jcraft__jsch__0.1.50.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.jolbox--bonecp--com.jolbox__bonecp__0.8.0.RELEASE.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.lihaoyi--sourcecode_2.12--com.lihaoyi__sourcecode_2.12__0.1.9.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.microsoft.azure--azure-data-lake-store-sdk--com.microsoft.azure__azure-data-lake-store-sdk__2.3.9.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.ning--compress-lzf--com.ning__compress-lzf__1.0.3.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.sun.mail--javax.mail--com.sun.mail__javax.mail__1.5.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.tdunning--json--com.tdunning__json__1.8.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.thoughtworks.paranamer--paranamer--com.thoughtworks.paranamer__paranamer__2.8.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.trueaccord.lenses--lenses_2.12--com.trueaccord.lenses__lenses_2.12__0.4.12.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.twitter--chill-java--com.twitter__chill-java__0.9.5.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.twitter--chill_2.12--com.twitter__chill_2.12__0.9.5.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.twitter--util-app_2.12--com.twitter__util-app_2.12__7.1.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.twitter--util-core_2.12--com.twitter__util-core_2.12__7.1.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.twitter--util-function_2.12--com.twitter__util-function_2.12__7.1.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.twitter--util-jvm_2.12--com.twitter__util-jvm_2.12__7.1.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.twitter--util-lint_2.12--com.twitter__util-lint_2.12__7.1.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.twitter--util-registry_2.12--com.twitter__util-registry_2.12__7.1.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.twitter--util-stats_2.12--com.twitter__util-stats_2.12__7.1.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.typesafe--config--com.typesafe__config__1.2.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.typesafe.scala-logging--scala-logging_2.12--com.typesafe.scala-logging__scala-logging_2.12__3.7.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.univocity--univocity-parsers--com.univocity__univocity-parsers__2.9.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.zaxxer--HikariCP--com.zaxxer__HikariCP__3.1.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-beanutils--commons-beanutils--commons-beanutils__commons-beanutils__1.9.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-cli--commons-cli--commons-cli__commons-cli__1.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-codec--commons-codec--commons-codec__commons-codec__1.10.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-collections--commons-collections--commons-collections__commons-collections__3.2.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-configuration--commons-configuration--commons-configuration__commons-configuration__1.6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-dbcp--commons-dbcp--commons-dbcp__commons-dbcp__1.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-digester--commons-digester--commons-digester__commons-digester__1.8.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-fileupload--commons-fileupload--commons-fileupload__commons-fileupload__1.3.3.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-httpclient--commons-httpclient--commons-httpclient__commons-httpclient__3.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-io--commons-io--commons-io__commons-io__2.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-lang--commons-lang--commons-lang__commons-lang__2.6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-logging--commons-logging--commons-logging__commons-logging__1.1.3.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-net--commons-net--commons-net__commons-net__3.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-pool--commons-pool--commons-pool__commons-pool__1.5.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--info.ganglia.gmetric4j--gmetric4j--info.ganglia.gmetric4j__gmetric4j__1.0.10.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.airlift--aircompressor--io.airlift__aircompressor__0.10.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.dropwizard.metrics--metrics-core--io.dropwizard.metrics__metrics-core__4.1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.dropwizard.metrics--metrics-graphite--io.dropwizard.metrics__metrics-graphite__4.1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.dropwizard.metrics--metrics-healthchecks--io.dropwizard.metrics__metrics-healthchecks__4.1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.dropwizard.metrics--metrics-jetty9--io.dropwizard.metrics__metrics-jetty9__4.1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.dropwizard.metrics--metrics-jmx--io.dropwizard.metrics__metrics-jmx__4.1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.dropwizard.metrics--metrics-json--io.dropwizard.metrics__metrics-json__4.1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.dropwizard.metrics--metrics-jvm--io.dropwizard.metrics__metrics-jvm__4.1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.dropwizard.metrics--metrics-servlets--io.dropwizard.metrics__metrics-servlets__4.1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.netty--netty-all--io.netty__netty-all__4.1.51.Final.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.prometheus--simpleclient--io.prometheus__simpleclient__0.7.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.prometheus--simpleclient_common--io.prometheus__simpleclient_common__0.7.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.prometheus--simpleclient_dropwizard--io.prometheus__simpleclient_dropwizard__0.7.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.prometheus--simpleclient_pushgateway--io.prometheus__simpleclient_pushgateway__0.7.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.prometheus--simpleclient_servlet--io.prometheus__simpleclient_servlet__0.7.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.prometheus.jmx--collector--io.prometheus.jmx__collector__0.12.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--jakarta.annotation--jakarta.annotation-api--jakarta.annotation__jakarta.annotation-api__1.3.5.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--jakarta.validation--jakarta.validation-api--jakarta.validation__jakarta.validation-api__2.0.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--jakarta.ws.rs--jakarta.ws.rs-api--jakarta.ws.rs__jakarta.ws.rs-api__2.1.6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--javax.activation--activation--javax.activation__activation__1.1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--javax.el--javax.el-api--javax.el__javax.el-api__2.2.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--javax.jdo--jdo-api--javax.jdo__jdo-api__3.0.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--javax.servlet--javax.servlet-api--javax.servlet__javax.servlet-api__3.1.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--javax.servlet.jsp--jsp-api--javax.servlet.jsp__jsp-api__2.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--javax.transaction--jta--javax.transaction__jta__1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--javax.transaction--transaction-api--javax.transaction__transaction-api__1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--javax.xml.bind--jaxb-api--javax.xml.bind__jaxb-api__2.2.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--javax.xml.stream--stax-api--javax.xml.stream__stax-api__1.0-2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--javolution--javolution--javolution__javolution__5.5.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--jets3t-0.7--com.databricks--jets3t--com.databricks__jets3t__0.7.1-0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--jets3t-0.7--liball_deps_2.12.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--jline--jline--jline__jline__2.14.6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--joda-time--joda-time--joda-time__joda-time__2.10.5.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--liball_deps_2.12.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--log4j--apache-log4j-extras--log4j__apache-log4j-extras__1.2.17.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--log4j--log4j--log4j__log4j__1.2.17.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--net.razorvine--pyrolite--net.razorvine__pyrolite__4.30.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--net.sf.jpam--jpam--net.sf.jpam__jpam__1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--net.sf.opencsv--opencsv--net.sf.opencsv__opencsv__2.3.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--net.sf.supercsv--super-csv--net.sf.supercsv__super-csv__2.2.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--net.snowflake--snowflake-ingest-sdk--net.snowflake__snowflake-ingest-sdk__0.9.6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--net.snowflake--snowflake-jdbc--net.snowflake__snowflake-jdbc__3.12.8.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--net.snowflake--spark-snowflake_2.12--net.snowflake__spark-snowflake_2.12__2.8.1-spark_3.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--net.sourceforge.f2j--arpack_combined_all--net.sourceforge.f2j__arpack_combined_all__0.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.acplt.remotetea--remotetea-oncrpc--org.acplt.remotetea__remotetea-oncrpc__1.1.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.antlr--ST4--org.antlr__ST4__4.0.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.antlr--antlr-runtime--org.antlr__antlr-runtime__3.5.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.antlr--antlr4-runtime--org.antlr__antlr4-runtime__4.8-1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.antlr--stringtemplate--org.antlr__stringtemplate__3.2.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.ant--ant--org.apache.ant__ant__1.9.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.ant--ant-jsch--org.apache.ant__ant-jsch__1.9.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.ant--ant-launcher--org.apache.ant__ant-launcher__1.9.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.arrow--arrow-format--org.apache.arrow__arrow-format__2.0.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.arrow--arrow-memory-core--org.apache.arrow__arrow-memory-core__2.0.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.arrow--arrow-memory-netty--org.apache.arrow__arrow-memory-netty__2.0.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.arrow--arrow-vector--org.apache.arrow__arrow-vector__2.0.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.avro--avro--org.apache.avro__avro__1.8.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.avro--avro-ipc--org.apache.avro__avro-ipc__1.8.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.avro--avro-mapred-hadoop2--org.apache.avro__avro-mapred-hadoop2__1.8.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.commons--commons-compress--org.apache.commons__commons-compress__1.20.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.commons--commons-crypto--org.apache.commons__commons-crypto__1.1.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.commons--commons-lang3--org.apache.commons__commons-lang3__3.10.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.commons--commons-math3--org.apache.commons__commons-math3__3.4.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.commons--commons-text--org.apache.commons__commons-text__1.6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.curator--curator-client--org.apache.curator__curator-client__2.7.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.curator--curator-framework--org.apache.curator__curator-framework__2.7.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.curator--curator-recipes--org.apache.curator__curator-recipes__2.7.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.derby--derby--org.apache.derby__derby__10.12.1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.directory.api--api-asn1-api--org.apache.directory.api__api-asn1-api__1.0.0-M20.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.directory.api--api-util--org.apache.directory.api__api-util__1.0.0-M20.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.directory.server--apacheds-i18n--org.apache.directory.server__apacheds-i18n__2.0.0-M15.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.directory.server--apacheds-kerberos-codec--org.apache.directory.server__apacheds-kerberos-codec__2.0.0-M15.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-annotations--org.apache.hadoop__hadoop-annotations__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-auth--org.apache.hadoop__hadoop-auth__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-client--org.apache.hadoop__hadoop-client__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-common--org.apache.hadoop__hadoop-common__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-hdfs--org.apache.hadoop__hadoop-hdfs__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-mapreduce-client-app--org.apache.hadoop__hadoop-mapreduce-client-app__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-mapreduce-client-common--org.apache.hadoop__hadoop-mapreduce-client-common__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-mapreduce-client-core--org.apache.hadoop__hadoop-mapreduce-client-core__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-mapreduce-client-jobclient--org.apache.hadoop__hadoop-mapreduce-client-jobclient__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-mapreduce-client-shuffle--org.apache.hadoop__hadoop-mapreduce-client-shuffle__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-yarn-api--org.apache.hadoop__hadoop-yarn-api__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-yarn-client--org.apache.hadoop__hadoop-yarn-client__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-yarn-common--org.apache.hadoop__hadoop-yarn-common__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-yarn-server-common--org.apache.hadoop__hadoop-yarn-server-common__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-beeline--org.apache.hive__hive-beeline__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-cli--org.apache.hive__hive-cli__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-common--org.apache.hive__hive-common__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-exec-core--org.apache.hive__hive-exec-core__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-jdbc--org.apache.hive__hive-jdbc__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-llap-client--org.apache.hive__hive-llap-client__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-llap-common--org.apache.hive__hive-llap-common__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-metastore--org.apache.hive__hive-metastore__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-serde--org.apache.hive__hive-serde__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-shims--org.apache.hive__hive-shims__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-storage-api--org.apache.hive__hive-storage-api__2.7.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-vector-code-gen--org.apache.hive__hive-vector-code-gen__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive.shims--hive-shims-0.23--org.apache.hive.shims__hive-shims-0.23__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive.shims--hive-shims-common--org.apache.hive.shims__hive-shims-common__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive.shims--hive-shims-scheduler--org.apache.hive.shims__hive-shims-scheduler__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.htrace--htrace-core--org.apache.htrace__htrace-core__3.1.0-incubating.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.httpcomponents--httpclient--org.apache.httpcomponents__httpclient__4.5.6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.httpcomponents--httpcore--org.apache.httpcomponents__httpcore__4.4.12.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.ivy--ivy--org.apache.ivy__ivy__2.4.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.mesos--mesos-shaded-protobuf--org.apache.mesos__mesos-shaded-protobuf__1.4.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.orc--orc-core--org.apache.orc__orc-core__1.5.12.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.orc--orc-mapreduce--org.apache.orc__orc-mapreduce__1.5.12.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.orc--orc-shims--org.apache.orc__orc-shims__1.5.12.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.parquet--parquet-column--org.apache.parquet__parquet-column__1.10.1-databricks6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.parquet--parquet-common--org.apache.parquet__parquet-common__1.10.1-databricks6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.parquet--parquet-encoding--org.apache.parquet__parquet-encoding__1.10.1-databricks6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.parquet--parquet-format--org.apache.parquet__parquet-format__2.4.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.parquet--parquet-hadoop--org.apache.parquet__parquet-hadoop__1.10.1-databricks6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.parquet--parquet-jackson--org.apache.parquet__parquet-jackson__1.10.1-databricks6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.thrift--libfb303--org.apache.thrift__libfb303__0.9.3.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.thrift--libthrift--org.apache.thrift__libthrift__0.12.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.velocity--velocity--org.apache.velocity__velocity__1.5.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.xbean--xbean-asm7-shaded--org.apache.xbean__xbean-asm7-shaded__4.15.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.codehaus.jackson--jackson-core-asl--org.codehaus.jackson__jackson-core-asl__1.9.13.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.codehaus.jackson--jackson-jaxrs--org.codehaus.jackson__jackson-jaxrs__1.9.13.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.codehaus.jackson--jackson-mapper-asl--org.codehaus.jackson__jackson-mapper-asl__1.9.13.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.codehaus.jackson--jackson-xc--org.codehaus.jackson__jackson-xc__1.9.13.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.codehaus.janino--commons-compiler--org.codehaus.janino__commons-compiler__3.0.16.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.codehaus.janino--janino--org.codehaus.janino__janino__3.0.16.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.datanucleus--datanucleus-api-jdo--org.datanucle\n*** WARNING: skipped 48806 bytes of output ***\n\n (&#39;spark.sql.hive.metastore.sharedPrefixes&#39;,\n  &#39;org.mariadb.jdbc,com.mysql.jdbc,org.postgresql,com.microsoft.sqlserver,microsoft.sql.DateTimeOffset,microsoft.sql.Types,com.databricks,com.codahale,com.fasterxml.jackson,shaded.databricks&#39;),\n (&#39;spark.databricks.io.directoryCommit.enableLogicalDelete&#39;, &#39;false&#39;),\n (&#39;spark.task.reaper.killTimeout&#39;, &#39;60s&#39;),\n (&#39;spark.r.numRBackendThreads&#39;, &#39;1&#39;),\n (&#39;spark.hadoop.fs.wasbs.impl.disable.cache&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.parquet.block.size.row.check.min&#39;, &#39;10&#39;),\n (&#39;spark.hadoop.hive.server2.use.SSL&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.fs.abfss.impl.disable.cache&#39;, &#39;true&#39;),\n (&#39;spark.databricks.workspace.multipleResults.enabled&#39;, &#39;true&#39;),\n (&#39;spark.sql.hive.metastore.version&#39;, &#39;0.13.0&#39;),\n (&#39;spark.shuffle.service.port&#39;, &#39;4048&#39;),\n (&#39;spark.databricks.clusterUsageTags.instanceWorkerEnvNetworkType&#39;, &#39;default&#39;),\n (&#39;spark.databricks.acl.client&#39;,\n  &#39;com.databricks.spark.sql.acl.client.SparkSqlAclClient&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterAvailability&#39;, &#39;ON_DEMAND&#39;),\n (&#39;spark.hadoop.hive.warehouse.subdir.inherit.perms&#39;, &#39;false&#39;),\n (&#39;spark.streaming.driver.writeAheadLog.closeFileAfterWrite&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterUsageTags.userProvidedRemoteVolumeSizeGb&#39;, &#39;0&#39;),\n (&#39;spark.hadoop.hive.server2.keystore.path&#39;,\n  &#39;/databricks/keys/jetty-ssl-driver-keystore.jks&#39;),\n (&#39;spark.databricks.clusterUsageTags.containerZoneId&#39;, &#39;us-west-2b&#39;),\n (&#39;spark.databricks.credential.redactor&#39;,\n  &#39;com.databricks.logging.secrets.CredentialRedactorProxyImpl&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterPinned&#39;, &#39;false&#39;),\n (&#39;spark.databricks.acl.provider&#39;,\n  &#39;com.databricks.sql.acl.ReflectionBackedAclProvider&#39;),\n (&#39;spark.hadoop.fs.s3n.impl&#39;,\n  &#39;shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystem&#39;),\n (&#39;spark.extraListeners&#39;,\n  &#39;com.databricks.backend.daemon.driver.DBCEventLoggingListener&#39;),\n (&#39;spark.databricks.clusterUsageTags.enableElasticDisk&#39;, &#39;false&#39;),\n (&#39;spark.hadoop.spark.databricks.io.parquet.verifyChecksumOnWrite.enabled&#39;,\n  &#39;false&#39;),\n (&#39;spark.sql.parquet.cacheMetadata&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterUsageTags.numPerGlobalInitScriptsV2&#39;, &#39;0&#39;),\n (&#39;spark.hadoop.fs.adl.impl&#39;, &#39;com.databricks.adl.AdlFileSystem&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterNodeType&#39;, &#39;dev-tier-node&#39;),\n (&#39;spark.hadoop.fs.cpfs-abfss.impl.disable.cache&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterUsageTags.enableLocalDiskEncryption&#39;, &#39;false&#39;),\n (&#39;spark.databricks.tahoe.logStore.class&#39;,\n  &#39;com.databricks.tahoe.store.DelegatingLogStore&#39;),\n (&#39;libraryDownload.sleepIntervalSeconds&#39;, &#39;5&#39;),\n (&#39;spark.databricks.cloudProvider&#39;, &#39;AWS&#39;),\n (&#39;spark.sql.hive.convertMetastoreParquet&#39;, &#39;true&#39;),\n (&#39;spark.executor.id&#39;, &#39;driver&#39;),\n (&#39;spark.databricks.passthrough.adls.tokenProviderClassName&#39;,\n  &#39;com.databricks.backend.daemon.data.client.adl.AdlCredentialContextTokenProvider&#39;),\n (&#39;spark.app.name&#39;, &#39;Databricks Shell&#39;),\n (&#39;spark.driver.allowMultipleContexts&#39;, &#39;false&#39;),\n (&#39;spark.databricks.clusterUsageTags.workerEnvironmentId&#39;,\n  &#39;default-worker-env&#39;),\n (&#39;spark.databricks.service.dbutils.server.backend&#39;,\n  &#39;com.databricks.dbconnect.SparkServerDBUtils&#39;),\n (&#39;spark.rdd.compress&#39;, &#39;true&#39;),\n (&#39;spark.databricks.repl.enableClassFileCleanup&#39;, &#39;true&#39;),\n (&#39;spark.databricks.eventLog.dir&#39;, &#39;eventlogs&#39;),\n (&#39;spark.databricks.driverNfs.pathSuffix&#39;, &#39;.ephemeral_nfs&#39;),\n (&#39;spark.sql.catalogImplementation&#39;, &#39;hive&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterCreator&#39;, &#39;Webapp&#39;),\n (&#39;spark.speculation&#39;, &#39;false&#39;),\n (&#39;spark.hadoop.fs.s3a.multipart.size&#39;, &#39;10485760&#39;),\n (&#39;spark.databricks.clusterUsageTags.cloudProvider&#39;, &#39;AWS&#39;),\n (&#39;spark.hadoop.databricks.dbfs.client.version&#39;, &#39;v1&#39;),\n (&#39;spark.hadoop.hive.server2.session.check.interval&#39;, &#39;60000&#39;),\n (&#39;spark.sql.hive.convertCTAS&#39;, &#39;true&#39;),\n (&#39;spark.metrics.conf&#39;, &#39;/databricks/spark/conf/metrics.properties&#39;),\n (&#39;spark.hadoop.spark.sql.parquet.output.committer.class&#39;,\n  &#39;org.apache.spark.sql.parquet.DirectParquetOutputCommitter&#39;),\n (&#39;spark.app.startTime&#39;, &#39;1623505979955&#39;),\n (&#39;spark.hadoop.fs.gs.impl&#39;,\n  &#39;shaded.databricks.V2_1_4.com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem&#39;),\n (&#39;spark.hadoop.fs.s3a.fast.upload.default&#39;, &#39;true&#39;),\n (&#39;spark.akka.frameSize&#39;, &#39;256&#39;),\n (&#39;spark.hadoop.fs.s3a.fast.upload&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterGeneration&#39;, &#39;0&#39;),\n (&#39;spark.hadoop.fs.abfs.impl.disable.cache&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.fs.wasbs.impl&#39;,\n  &#39;shaded.databricks.org.apache.hadoop.fs.azure.NativeAzureFileSystem&#39;),\n (&#39;spark.sql.streaming.stopTimeout&#39;, &#39;15s&#39;),\n (&#39;spark.hadoop.hive.server2.keystore.password&#39;, &#39;[REDACTED]&#39;),\n (&#39;spark.speculation.multiplier&#39;, &#39;3&#39;),\n (&#39;spark.storage.blockManagerTimeoutIntervalMs&#39;, &#39;300000&#39;),\n (&#39;spark.databricks.overrideDefaultCommitProtocol&#39;,\n  &#39;org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterOwnerOrgId&#39;, &#39;4173788838256447&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterNoDriverDaemon&#39;, &#39;false&#39;),\n (&#39;spark.databricks.clusterUsageTags.instanceWorkerEnvId&#39;,\n  &#39;default-worker-env&#39;),\n (&#39;libraryDownload.timeoutSeconds&#39;, &#39;180&#39;),\n (&#39;spark.hadoop.parquet.memory.pool.ratio&#39;, &#39;0.5&#39;),\n (&#39;spark.sparkr.use.daemon&#39;, &#39;false&#39;),\n (&#39;spark.scheduler.listenerbus.eventqueue.capacity&#39;, &#39;20000&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterScalingType&#39;, &#39;fixed_size&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterStateMessage&#39;, &#39;Starting Spark&#39;),\n (&#39;spark.sql.hive.metastore.jars&#39;, &#39;/databricks/hive/*&#39;),\n (&#39;spark.databricks.passthrough.adls.gen2.tokenProviderClassName&#39;,\n  &#39;com.databricks.backend.daemon.data.client.adl.AdlGen2CredentialContextTokenProvider&#39;),\n (&#39;spark.hadoop.parquet.page.write-checksum.enabled&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.databricks.s3commit.client.sslTrustAll&#39;, &#39;false&#39;),\n (&#39;spark.hadoop.fs.s3a.threads.max&#39;, &#39;136&#39;),\n (&#39;spark.r.backendConnectionTimeout&#39;, &#39;604800&#39;),\n (&#39;spark.databricks.tahoe.logStore.gcp.class&#39;,\n  &#39;com.databricks.tahoe.store.GCPLogStore&#39;),\n (&#39;spark.serializer.objectStreamReset&#39;, &#39;100&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterOwnerUserId&#39;, &#39;8377913310544237&#39;),\n (&#39;spark.sql.sources.commitProtocolClass&#39;,\n  &#39;com.databricks.sql.transaction.directory.DirectoryAtomicCommitProtocol&#39;),\n (&#39;spark.hadoop.fs.abfss.impl&#39;,\n  &#39;shaded.databricks.azurebfs.org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem&#39;),\n (&#39;spark.hadoop.hive.server2.idle.session.timeout&#39;, &#39;900000&#39;),\n (&#39;spark.databricks.redactor&#39;,\n  &#39;com.databricks.spark.util.DatabricksSparkLogRedactorProxy&#39;),\n (&#39;spark.databricks.clusterUsageTags.autoTerminationMinutes&#39;, &#39;120&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterPythonVersion&#39;, &#39;3&#39;),\n (&#39;spark.hadoop.fs.s3a.impl&#39;,\n  &#39;shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystem&#39;),\n (&#39;spark.databricks.clusterUsageTags.enableDfAcls&#39;, &#39;false&#39;),\n (&#39;spark.databricks.clusterUsageTags.userProvidedRemoteVolumeCount&#39;, &#39;0&#39;),\n (&#39;spark.shuffle.service.enabled&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.fs.cpfs-s3.impl&#39;,\n  &#39;com.databricks.sql.acl.fs.CredentialPassthroughFileSystem&#39;),\n (&#39;spark.hadoop.parquet.page.verify-checksum.enabled&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.fs.s3a.multipart.threshold&#39;, &#39;104857600&#39;),\n (&#39;spark.databricks.clusterUsageTags.dataPlaneRegion&#39;, &#39;us-west-2&#39;),\n (&#39;spark.rpc.message.maxSize&#39;, &#39;256&#39;),\n (&#39;spark.logConf&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterUsageTags.enableJobsAutostart&#39;, &#39;true&#39;),\n (&#39;spark.databricks.driverNfs.enabled&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterMetastoreAccessType&#39;,\n  &#39;RDS_DIRECT&#39;),\n (&#39;spark.hadoop.hive.server2.enable.doAs&#39;, &#39;false&#39;),\n (&#39;eventLog.rolloverIntervalSeconds&#39;, &#39;3600&#39;),\n (&#39;spark.databricks.clusterUsageTags.ngrokNpipEnabled&#39;, &#39;false&#39;),\n (&#39;spark.databricks.clusterUsageTags.instanceProfileUsed&#39;, &#39;false&#39;),\n (&#39;spark.shuffle.memoryFraction&#39;, &#39;0.2&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterAllTags&#39;,\n  &#39;[{&#34;key&#34;:&#34;Name&#34;,&#34;value&#34;:&#34;ce-worker&#34;}]&#39;),\n (&#39;spark.databricks.clusterUsageTags.driverInstanceId&#39;, &#39;i-063aee2d40ca68cb6&#39;),\n (&#39;spark.hadoop.fs.abfs.impl&#39;,\n  &#39;shaded.databricks.azurebfs.org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem&#39;),\n (&#39;spark.hadoop.fs.cpfs-s3a.impl&#39;,\n  &#39;com.databricks.sql.acl.fs.CredentialPassthroughFileSystem&#39;),\n (&#39;spark.r.sql.derby.temp.dir&#39;, &#39;/tmp/RtmpgbfILv&#39;),\n (&#39;spark.databricks.acl.scim.client&#39;,\n  &#39;com.databricks.spark.sql.acl.client.DriverToWebappScimClient&#39;),\n (&#39;spark.databricks.clusterUsageTags.region&#39;, &#39;us-west-2&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterSpotBidPricePercent&#39;, &#39;100&#39;)]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[4]: [(&#39;spark.files.useFetchCache&#39;, &#39;false&#39;),\n (&#39;spark.databricks.preemption.enabled&#39;, &#39;true&#39;),\n (&#39;spark.driver.tempDirectory&#39;, &#39;/local_disk0/tmp&#39;),\n (&#39;spark.hadoop.fs.adl.impl.disable.cache&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.parquet.block.size.row.check.max&#39;, &#39;10&#39;),\n (&#39;spark.hadoop.fs.s3a.connection.maximum&#39;, &#39;200&#39;),\n (&#39;spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2&#39;, &#39;0&#39;),\n (&#39;spark.executor.extraJavaOptions&#39;,\n  &#39;-Djava.io.tmpdir=/local_disk0/tmp -XX:ReservedCodeCacheSize=512m -XX:+UseCodeCacheFlushing -Djava.security.properties=/databricks/spark/dbconf/java/extra.security -XX:-UseContainerSupport -XX:+PrintFlagsFinal -XX:+PrintGCDateStamps -verbose:gc -XX:+PrintGCDetails -Xss4m -Djava.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni -Djavax.xml.datatype.DatatypeFactory=com.sun.org.apache.xerces.internal.jaxp.datatype.DatatypeFactoryImpl -Djavax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -Djavax.xml.validation.SchemaFactory:http://www.w3.org/2001/XMLSchema=com.sun.org.apache.xerces.internal.jaxp.validation.XMLSchemaFactory -Dorg.xml.sax.driver=com.sun.org.apache.xerces.internal.parsers.SAXParser -Dorg.w3c.dom.DOMImplementationSourceList=com.sun.org.apache.xerces.internal.dom.DOMXSImplementationSourceImpl -Djavax.net.ssl.sessionCacheSize=10000 -Dscala.reflect.runtime.disable.typetag.cache=true -Ddatabricks.serviceName=spark-executor-1&#39;),\n (&#39;spark.hadoop.fs.s3a.fast.upload.active.blocks&#39;, &#39;32&#39;),\n (&#39;spark.shuffle.reduceLocality.enabled&#39;, &#39;false&#39;),\n (&#39;spark.app.id&#39;, &#39;local-1623505984833&#39;),\n (&#39;spark.sql.streaming.checkpointFileManagerClass&#39;,\n  &#39;com.databricks.spark.sql.streaming.DatabricksCheckpointFileManager&#39;),\n (&#39;spark.databricks.clusterUsageTags.driverContainerId&#39;,\n  &#39;0ca6764af05147f896ebcb208e3e2dc3&#39;),\n (&#39;spark.databricks.service.dbutils.repl.backend&#39;,\n  &#39;com.databricks.dbconnect.ReplDBUtils&#39;),\n (&#39;spark.databricks.clusterUsageTags.driverNodeType&#39;, &#39;dev-tier-node&#39;),\n (&#39;spark.hadoop.spark.sql.sources.outputCommitterClass&#39;,\n  &#39;com.databricks.backend.daemon.data.client.MapReduceDirectOutputCommitter&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterName&#39;, &#39;sample&#39;),\n (&#39;spark.hadoop.fs.AbstractFileSystem.gs.impl&#39;,\n  &#39;shaded.databricks.V2_1_4.com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS&#39;),\n (&#39;spark.databricks.clusterUsageTags.instanceBootstrapType&#39;, &#39;ssh&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterId&#39;, &#39;0612-135218-toms290&#39;),\n (&#39;spark.streaming.driver.writeAheadLog.allowBatching&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterSource&#39;, &#39;UI&#39;),\n (&#39;spark.hadoop.hive.server2.transport.mode&#39;, &#39;http&#39;),\n (&#39;spark.hadoop.hive.server2.thrift.http.cookie.auth.enabled&#39;, &#39;false&#39;),\n (&#39;spark.executor.memory&#39;, &#39;8278m&#39;),\n (&#39;spark.databricks.driverNodeTypeId&#39;, &#39;dev-tier-node&#39;),\n (&#39;spark.sql.parquet.compression.codec&#39;, &#39;snappy&#39;),\n (&#39;spark.hadoop.fs.cpfs-adl.impl.disable.cache&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterUsageTags.hailEnabled&#39;, &#39;false&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterLogDeliveryEnabled&#39;, &#39;false&#39;),\n (&#39;spark.databricks.clusterUsageTags.containerType&#39;, &#39;LXC&#39;),\n (&#39;spark.eventLog.enabled&#39;, &#39;false&#39;),\n (&#39;spark.databricks.clusterUsageTags.isIMv2Enabled&#39;, &#39;false&#39;),\n (&#39;spark.databricks.cloudfetch.hasRegionSupport&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.databricks.s3.create.deleteUnnecessaryFakeDirectories&#39;,\n  &#39;false&#39;),\n (&#39;spark.hadoop.fs.wasb.impl&#39;,\n  &#39;shaded.databricks.org.apache.hadoop.fs.azure.NativeAzureFileSystem&#39;),\n (&#39;spark.executor.tempDirectory&#39;, &#39;/local_disk0/tmp&#39;),\n (&#39;spark.databricks.workerNodeTypeId&#39;, &#39;dev-tier-node&#39;),\n (&#39;spark.hadoop.mapred.output.committer.class&#39;,\n  &#39;com.databricks.backend.daemon.data.client.DirectOutputCommitter&#39;),\n (&#39;spark.hadoop.hive.server2.thrift.http.port&#39;, &#39;10000&#39;),\n (&#39;spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version&#39;, &#39;2&#39;),\n (&#39;spark.sql.allowMultipleContexts&#39;, &#39;false&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterEbsVolumeSize&#39;, &#39;0&#39;),\n (&#39;spark.home&#39;, &#39;/databricks/spark&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterTargetWorkers&#39;, &#39;0&#39;),\n (&#39;spark.driver.port&#39;, &#39;40703&#39;),\n (&#39;spark.sql.warehouse.dir&#39;, &#39;/user/hive/warehouse&#39;),\n (&#39;spark.hadoop.hive.server2.idle.operation.timeout&#39;, &#39;7200000&#39;),\n (&#39;spark.task.reaper.enabled&#39;, &#39;true&#39;),\n (&#39;spark.databricks.passthrough.s3a.tokenProviderClassName&#39;,\n  &#39;com.databricks.backend.daemon.driver.aws.AwsCredentialContextTokenProvider&#39;),\n (&#39;spark.storage.memoryFraction&#39;, &#39;0.5&#39;),\n (&#39;spark.databricks.session.share&#39;, &#39;false&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterResourceClass&#39;, &#39;default&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterFirstOnDemand&#39;, &#39;0&#39;),\n (&#39;spark.databricks.clusterUsageTags.driverContainerPrivateIp&#39;,\n  &#39;10.172.211.145&#39;),\n (&#39;spark.driver.maxResultSize&#39;, &#39;4g&#39;),\n (&#39;spark.repl.class.outputDir&#39;,\n  &#39;/local_disk0/tmp/repl/spark-6327425981576752428-cc68f4a7-003b-4500-b6e9-83fe01b8c51c&#39;),\n (&#39;spark.databricks.delta.multiClusterWrites.enabled&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterUsageTags.driverPublicDns&#39;,\n  &#39;ec2-34-219-166-254.us-west-2.compute.amazonaws.com&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterSku&#39;, &#39;STANDARD_SKU&#39;),\n (&#39;spark.worker.cleanup.enabled&#39;, &#39;false&#39;),\n (&#39;spark.sql.legacy.createHiveTableByDefault&#39;, &#39;false&#39;),\n (&#39;spark.hadoop.fs.gs.impl.disable.cache&#39;, &#39;true&#39;),\n (&#39;spark.databricks.workspace.matplotlibInline.enabled&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterUsageTags.sparkVersion&#39;, &#39;8.2.x-scala2.12&#39;),\n (&#39;spark.databricks.clusterUsageTags.enableCredentialPassthrough&#39;, &#39;false&#39;),\n (&#39;spark.databricks.clusterUsageTags.driverInstancePrivateIp&#39;,\n  &#39;10.172.212.157&#39;),\n (&#39;spark.databricks.clusterUsageTags.enableJdbcAutoStart&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterUsageTags.userProvidedRemoteVolumeType&#39;,\n  &#39;ebs_volume_type: GENERAL_PURPOSE_SSD\\n&#39;),\n (&#39;spark.hadoop.fs.wasb.impl.disable.cache&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterEbsVolumeType&#39;,\n  &#39;GENERAL_PURPOSE_SSD&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterLogDestination&#39;, &#39;&#39;),\n (&#39;spark.cleaner.referenceTracking.blocking&#39;, &#39;false&#39;),\n (&#39;spark.hadoop.parquet.page.size.check.estimate&#39;, &#39;false&#39;),\n (&#39;spark.hadoop.spark.driverproxy.customHeadersToProperties&#39;,\n  &#39;X-Databricks-User-Token:spark.databricks.token,X-Databricks-Api-Url:spark.databricks.api.url,X-Databricks-ADLS-Gen1-Token:spark.databricks.adls.gen1.token,X-Databricks-ADLS-Gen2-Token:spark.databricks.adls.gen2.token,X-Databricks-Synapse-Token:spark.databricks.synapse.token,X-Databricks-AWS-Credentials:spark.databricks.aws.creds,X-Databricks-User-Id:spark.databricks.user.id,X-Databricks-User-Name:spark.databricks.user.name&#39;),\n (&#39;spark.databricks.passthrough.s3a.threadPoolExecutor.factory.class&#39;,\n  &#39;com.databricks.backend.daemon.driver.aws.S3APassthroughThreadPoolExecutorFactory&#39;),\n (&#39;spark.repl.class.uri&#39;, &#39;spark://10.172.211.145:40703/classes&#39;),\n (&#39;spark.databricks.clusterUsageTags.isSingleUserCluster&#39;, &#39;false&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterState&#39;, &#39;Pending&#39;),\n (&#39;spark.databricks.tahoe.logStore.azure.class&#39;,\n  &#39;com.databricks.tahoe.store.AzureLogStore&#39;),\n (&#39;spark.databricks.delta.preview.enabled&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.fs.azure.skip.metrics&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.fs.s3.impl&#39;,\n  &#39;shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystem&#39;),\n (&#39;spark.databricks.cloudfetch.requesterClassName&#39;,\n  &#39;com.databricks.spark.sql.cloudfetch.DataDaemonCloudPresignedUrlRequester&#39;),\n (&#39;spark.master&#39;, &#39;local[8]&#39;),\n (&#39;spark.scheduler.mode&#39;, &#39;FAIR&#39;),\n (&#39;spark.sql.sources.default&#39;, &#39;delta&#39;),\n (&#39;spark.databricks.delta.logStore.crossCloud.fatal&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.fs.cpfs-s3n.impl&#39;,\n  &#39;com.databricks.sql.acl.fs.CredentialPassthroughFileSystem&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterWorkers&#39;, &#39;0&#39;),\n (&#39;spark.hadoop.fs.cpfs-adl.impl&#39;,\n  &#39;com.databricks.sql.acl.fs.CredentialPassthroughFileSystem&#39;),\n (&#39;spark.files.fetchFailure.unRegisterOutputOnHost&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.fs.cpfs-abfss.impl&#39;,\n  &#39;com.databricks.sql.acl.fs.CredentialPassthroughFileSystem&#39;),\n (&#39;spark.databricks.sparkContextId&#39;, &#39;6327425981576752428&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterEbsVolumeCount&#39;, &#39;0&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterNumSshKeys&#39;, &#39;0&#39;),\n (&#39;spark.ui.port&#39;, &#39;46321&#39;),\n (&#39;spark.databricks.clusterUsageTags.enableSqlAclsOnly&#39;, &#39;false&#39;),\n (&#39;spark.hadoop.fs.gs.outputstream.upload.chunk.size&#39;, &#39;16777216&#39;),\n (&#39;spark.databricks.tahoe.logStore.aws.class&#39;,\n  &#39;com.databricks.tahoe.store.S3LockBasedLogStore&#39;),\n (&#39;spark.speculation.quantile&#39;, &#39;0.9&#39;),\n (&#39;spark.databricks.clusterUsageTags.privateLinkEnabled&#39;, &#39;false&#39;),\n (&#39;spark.shuffle.manager&#39;, &#39;SORT&#39;),\n (&#39;spark.files.overwrite&#39;, &#39;true&#39;),\n (&#39;spark.driver.host&#39;, &#39;10.172.211.145&#39;),\n (&#39;spark.executor.extraClassPath&#39;,\n  &#39;/databricks/spark/dbconf/log4j/executor:/databricks/spark/dbconf/jets3t/:/databricks/spark/dbconf/hadoop:/databricks/hive/conf:/databricks/jars/----jackson_annotations_shaded--libjackson-annotations.jar:/databricks/jars/----jackson_core_shaded--libjackson-core.jar:/databricks/jars/----jackson_databind_shaded--libjackson-databind.jar:/databricks/jars/----jackson_datatype_joda_shaded--libjackson-datatype-joda.jar:/databricks/jars/----scalapb_090--com.lihaoyi__fastparse_2.12__2.1.3_shaded.jar:/databricks/jars/----scalapb_090--com.lihaoyi__sourcecode_2.12__0.1.7_shaded.jar:/databricks/jars/----scalapb_090--runtime-unshaded-jetty9-hadoop1_2.12_deploy_shaded.jar:/databricks/jars/----workspace_spark_3_1--common--kvstore--kvstore-hive-2.3__hadoop-2.7_2.12_deploy.jar:/databricks/jars/----workspace_spark_3_1--common--network-common--network-common-hive-2.3__hadoop-2.7_2.12_deploy.jar:/databricks/jars/----workspace_spark_3_1--common--network-shuffle--network-shuffle-hive-2.3__hadoop-2.7_2.12_deploy.jar:/databricks/jars/----workspace_spark_3_1--common--sketch--sketch-hive-2.3__hadoop-2.7_2.12_deploy.jar:/databricks/jars/----workspace_spark_3_1--common--tags--tags-hive-2.3__hadoop-2.7_2.12_deploy.jar:/databricks/jars/----workspace_spark_3_1--common--unsafe--unsafe-hive-2.3__hadoop-2.7_2.12_deploy.jar:/databricks/jars/----workspace_spark_3_1--core--core-hive-2.3__hadoop-2.7_2.12_deploy.jar:/databricks/jars/----workspace_spark_3_1--core--libcore_generated_resources.jar:/databricks/jars/----workspace_spark_3_1--core--libcore_resources.jar:/databricks/jars/----workspace_spark_3_1--core--proto-hive-2.3__hadoop-2.7_2.12_deploy.jar:/databricks/jars/----workspace_spark_3_1--graphx--graphx-hive-2.3__hadoop-2.7_2.12_deploy.jar:/databricks/jars/----workspace_spark_3_1--launcher--launcher-hive-2.3__hadoop-2.7_2.12_deploy.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--antlr--antlr--antlr__antlr__2.7.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--amazon-kinesis-client--com.amazonaws__amazon-kinesis-client__1.12.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-autoscaling--com.amazonaws__aws-java-sdk-autoscaling__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-cloudformation--com.amazonaws__aws-java-sdk-cloudformation__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-cloudfront--com.amazonaws__aws-java-sdk-cloudfront__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-cloudhsm--com.amazonaws__aws-java-sdk-cloudhsm__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-cloudsearch--com.amazonaws__aws-java-sdk-cloudsearch__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-cloudtrail--com.amazonaws__aws-java-sdk-cloudtrail__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-cloudwatch--com.amazonaws__aws-java-sdk-cloudwatch__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-cloudwatchmetrics--com.amazonaws__aws-java-sdk-cloudwatchmetrics__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-codedeploy--com.amazonaws__aws-java-sdk-codedeploy__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-cognitoidentity--com.amazonaws__aws-java-sdk-cognitoidentity__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-cognitosync--com.amazonaws__aws-java-sdk-cognitosync__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-config--com.amazonaws__aws-java-sdk-config__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-core--com.amazonaws__aws-java-sdk-core__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-datapipeline--com.amazonaws__aws-java-sdk-datapipeline__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-directconnect--com.amazonaws__aws-java-sdk-directconnect__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-directory--com.amazonaws__aws-java-sdk-directory__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-dynamodb--com.amazonaws__aws-java-sdk-dynamodb__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-ec2--com.amazonaws__aws-java-sdk-ec2__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-ecs--com.amazonaws__aws-java-sdk-ecs__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-efs--com.amazonaws__aws-java-sdk-efs__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-elasticache--com.amazonaws__aws-java-sdk-elasticache__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-elasticbeanstalk--com.amazonaws__aws-java-sdk-elasticbeanstalk__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-elasticloadbalancing--com.amazonaws__aws-java-sdk-elasticloadbalancing__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-elastictranscoder--com.amazonaws__aws-java-sdk-elastictranscoder__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-emr--com.amazonaws__aws-java-sdk-emr__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-glacier--com.amazonaws__aws-java-sdk-glacier__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-iam--com.amazonaws__aws-java-sdk-iam__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-importexport--com.amazonaws__aws-java-sdk-importexport__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-kinesis--com.amazonaws__aws-java-sdk-kinesis__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-kms--com.amazonaws__aws-java-sdk-kms__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-lambda--com.amazonaws__aws-java-sdk-lambda__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-logs--com.amazonaws__aws-java-sdk-logs__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-machinelearning--com.amazonaws__aws-java-sdk-machinelearning__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-opsworks--com.amazonaws__aws-java-sdk-opsworks__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-rds--com.amazonaws__aws-java-sdk-rds__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-redshift--com.amazonaws__aws-java-sdk-redshift__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-route53--com.amazonaws__aws-java-sdk-route53__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-s3--com.amazonaws__aws-java-sdk-s3__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-ses--com.amazonaws__aws-java-sdk-ses__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-simpledb--com.amazonaws__aws-java-sdk-simpledb__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-simpleworkflow--com.amazonaws__aws-java-sdk-simpleworkflow__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-sns--com.amazonaws__aws-java-sdk-sns__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-sqs--com.amazonaws__aws-java-sdk-sqs__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-ssm--com.amazonaws__aws-java-sdk-ssm__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-storagegateway--com.amazonaws__aws-java-sdk-storagegateway__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-sts--com.amazonaws__aws-java-sdk-sts__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-support--com.amazonaws__aws-java-sdk-support__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-swf-libraries--com.amazonaws__aws-java-sdk-swf-libraries__1.11.22.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--aws-java-sdk-workspaces--com.amazonaws__aws-java-sdk-workspaces__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.amazonaws--jmespath-java--com.amazonaws__jmespath-java__1.11.655.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.chuusai--shapeless_2.12--com.chuusai__shapeless_2.12__2.3.3.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.clearspring.analytics--stream--com.clearspring.analytics__stream__2.9.6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.databricks--Rserve--com.databricks__Rserve__1.8-3.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.databricks.scalapb--compilerplugin_2.12--com.databricks.scalapb__compilerplugin_2.12__0.4.15-10.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.databricks.scalapb--scalapb-runtime_2.12--com.databricks.scalapb__scalapb-runtime_2.12__0.4.15-10.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.esotericsoftware--kryo-shaded--com.esotericsoftware__kryo-shaded__4.0.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.esotericsoftware--minlog--com.esotericsoftware__minlog__1.3.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.fasterxml--classmate--com.fasterxml__classmate__1.3.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.fasterxml.jackson.core--jackson-annotations--com.fasterxml.jackson.core__jackson-annotations__2.10.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.fasterxml.jackson.core--jackson-core--com.fasterxml.jackson.core__jackson-core__2.10.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.fasterxml.jackson.core--jackson-databind--com.fasterxml.jackson.core__jackson-databind__2.10.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.fasterxml.jackson.dataformat--jackson-dataformat-cbor--com.fasterxml.jackson.dataformat__jackson-dataformat-cbor__2.10.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.fasterxml.jackson.datatype--jackson-datatype-joda--com.fasterxml.jackson.datatype__jackson-datatype-joda__2.10.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.fasterxml.jackson.module--jackson-module-paranamer--com.fasterxml.jackson.module__jackson-module-paranamer__2.10.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.fasterxml.jackson.module--jackson-module-scala_2.12--com.fasterxml.jackson.module__jackson-module-scala_2.12__2.10.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.ben-manes.caffeine--caffeine--com.github.ben-manes.caffeine__caffeine__2.3.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.fommil--jniloader--com.github.fommil__jniloader__1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.fommil.netlib--core--com.github.fommil.netlib__core__1.1.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.fommil.netlib--native_ref-java--com.github.fommil.netlib__native_ref-java__1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.fommil.netlib--native_ref-java-natives--com.github.fommil.netlib__native_ref-java-natives__1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.fommil.netlib--native_system-java--com.github.fommil.netlib__native_system-java__1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.fommil.netlib--native_system-java-natives--com.github.fommil.netlib__native_system-java-natives__1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.fommil.netlib--netlib-native_ref-linux-x86_64-natives--com.github.fommil.netlib__netlib-native_ref-linux-x86_64-natives__1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.fommil.netlib--netlib-native_system-linux-x86_64-natives--com.github.fommil.netlib__netlib-native_system-linux-x86_64-natives__1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.joshelser--dropwizard-metrics-hadoop-metrics2-reporter--com.github.joshelser__dropwizard-metrics-hadoop-metrics2-reporter__0.1.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.luben--zstd-jni--com.github.luben__zstd-jni__1.4.8-1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.github.wendykierp--JTransforms--com.github.wendykierp__JTransforms__3.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.google.code.findbugs--jsr305--com.google.code.findbugs__jsr305__3.0.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.google.code.gson--gson--com.google.code.gson__gson__2.2.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.google.flatbuffers--flatbuffers-java--com.google.flatbuffers__flatbuffers-java__1.9.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.google.guava--guava--com.google.guava__guava__15.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.google.protobuf--protobuf-java--com.google.protobuf__protobuf-java__2.6.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.h2database--h2--com.h2database__h2__1.4.195.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.helger--profiler--com.helger__profiler__1.1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.jcraft--jsch--com.jcraft__jsch__0.1.50.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.jolbox--bonecp--com.jolbox__bonecp__0.8.0.RELEASE.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.lihaoyi--sourcecode_2.12--com.lihaoyi__sourcecode_2.12__0.1.9.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.microsoft.azure--azure-data-lake-store-sdk--com.microsoft.azure__azure-data-lake-store-sdk__2.3.9.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.ning--compress-lzf--com.ning__compress-lzf__1.0.3.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.sun.mail--javax.mail--com.sun.mail__javax.mail__1.5.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.tdunning--json--com.tdunning__json__1.8.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.thoughtworks.paranamer--paranamer--com.thoughtworks.paranamer__paranamer__2.8.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.trueaccord.lenses--lenses_2.12--com.trueaccord.lenses__lenses_2.12__0.4.12.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.twitter--chill-java--com.twitter__chill-java__0.9.5.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.twitter--chill_2.12--com.twitter__chill_2.12__0.9.5.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.twitter--util-app_2.12--com.twitter__util-app_2.12__7.1.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.twitter--util-core_2.12--com.twitter__util-core_2.12__7.1.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.twitter--util-function_2.12--com.twitter__util-function_2.12__7.1.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.twitter--util-jvm_2.12--com.twitter__util-jvm_2.12__7.1.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.twitter--util-lint_2.12--com.twitter__util-lint_2.12__7.1.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.twitter--util-registry_2.12--com.twitter__util-registry_2.12__7.1.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.twitter--util-stats_2.12--com.twitter__util-stats_2.12__7.1.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.typesafe--config--com.typesafe__config__1.2.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.typesafe.scala-logging--scala-logging_2.12--com.typesafe.scala-logging__scala-logging_2.12__3.7.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.univocity--univocity-parsers--com.univocity__univocity-parsers__2.9.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--com.zaxxer--HikariCP--com.zaxxer__HikariCP__3.1.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-beanutils--commons-beanutils--commons-beanutils__commons-beanutils__1.9.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-cli--commons-cli--commons-cli__commons-cli__1.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-codec--commons-codec--commons-codec__commons-codec__1.10.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-collections--commons-collections--commons-collections__commons-collections__3.2.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-configuration--commons-configuration--commons-configuration__commons-configuration__1.6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-dbcp--commons-dbcp--commons-dbcp__commons-dbcp__1.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-digester--commons-digester--commons-digester__commons-digester__1.8.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-fileupload--commons-fileupload--commons-fileupload__commons-fileupload__1.3.3.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-httpclient--commons-httpclient--commons-httpclient__commons-httpclient__3.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-io--commons-io--commons-io__commons-io__2.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-lang--commons-lang--commons-lang__commons-lang__2.6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-logging--commons-logging--commons-logging__commons-logging__1.1.3.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-net--commons-net--commons-net__commons-net__3.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--commons-pool--commons-pool--commons-pool__commons-pool__1.5.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--info.ganglia.gmetric4j--gmetric4j--info.ganglia.gmetric4j__gmetric4j__1.0.10.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.airlift--aircompressor--io.airlift__aircompressor__0.10.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.dropwizard.metrics--metrics-core--io.dropwizard.metrics__metrics-core__4.1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.dropwizard.metrics--metrics-graphite--io.dropwizard.metrics__metrics-graphite__4.1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.dropwizard.metrics--metrics-healthchecks--io.dropwizard.metrics__metrics-healthchecks__4.1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.dropwizard.metrics--metrics-jetty9--io.dropwizard.metrics__metrics-jetty9__4.1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.dropwizard.metrics--metrics-jmx--io.dropwizard.metrics__metrics-jmx__4.1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.dropwizard.metrics--metrics-json--io.dropwizard.metrics__metrics-json__4.1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.dropwizard.metrics--metrics-jvm--io.dropwizard.metrics__metrics-jvm__4.1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.dropwizard.metrics--metrics-servlets--io.dropwizard.metrics__metrics-servlets__4.1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.netty--netty-all--io.netty__netty-all__4.1.51.Final.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.prometheus--simpleclient--io.prometheus__simpleclient__0.7.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.prometheus--simpleclient_common--io.prometheus__simpleclient_common__0.7.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.prometheus--simpleclient_dropwizard--io.prometheus__simpleclient_dropwizard__0.7.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.prometheus--simpleclient_pushgateway--io.prometheus__simpleclient_pushgateway__0.7.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.prometheus--simpleclient_servlet--io.prometheus__simpleclient_servlet__0.7.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--io.prometheus.jmx--collector--io.prometheus.jmx__collector__0.12.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--jakarta.annotation--jakarta.annotation-api--jakarta.annotation__jakarta.annotation-api__1.3.5.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--jakarta.validation--jakarta.validation-api--jakarta.validation__jakarta.validation-api__2.0.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--jakarta.ws.rs--jakarta.ws.rs-api--jakarta.ws.rs__jakarta.ws.rs-api__2.1.6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--javax.activation--activation--javax.activation__activation__1.1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--javax.el--javax.el-api--javax.el__javax.el-api__2.2.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--javax.jdo--jdo-api--javax.jdo__jdo-api__3.0.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--javax.servlet--javax.servlet-api--javax.servlet__javax.servlet-api__3.1.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--javax.servlet.jsp--jsp-api--javax.servlet.jsp__jsp-api__2.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--javax.transaction--jta--javax.transaction__jta__1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--javax.transaction--transaction-api--javax.transaction__transaction-api__1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--javax.xml.bind--jaxb-api--javax.xml.bind__jaxb-api__2.2.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--javax.xml.stream--stax-api--javax.xml.stream__stax-api__1.0-2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--javolution--javolution--javolution__javolution__5.5.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--jets3t-0.7--com.databricks--jets3t--com.databricks__jets3t__0.7.1-0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--jets3t-0.7--liball_deps_2.12.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--jline--jline--jline__jline__2.14.6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--joda-time--joda-time--joda-time__joda-time__2.10.5.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--liball_deps_2.12.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--log4j--apache-log4j-extras--log4j__apache-log4j-extras__1.2.17.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--log4j--log4j--log4j__log4j__1.2.17.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--net.razorvine--pyrolite--net.razorvine__pyrolite__4.30.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--net.sf.jpam--jpam--net.sf.jpam__jpam__1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--net.sf.opencsv--opencsv--net.sf.opencsv__opencsv__2.3.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--net.sf.supercsv--super-csv--net.sf.supercsv__super-csv__2.2.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--net.snowflake--snowflake-ingest-sdk--net.snowflake__snowflake-ingest-sdk__0.9.6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--net.snowflake--snowflake-jdbc--net.snowflake__snowflake-jdbc__3.12.8.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--net.snowflake--spark-snowflake_2.12--net.snowflake__spark-snowflake_2.12__2.8.1-spark_3.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--net.sourceforge.f2j--arpack_combined_all--net.sourceforge.f2j__arpack_combined_all__0.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.acplt.remotetea--remotetea-oncrpc--org.acplt.remotetea__remotetea-oncrpc__1.1.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.antlr--ST4--org.antlr__ST4__4.0.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.antlr--antlr-runtime--org.antlr__antlr-runtime__3.5.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.antlr--antlr4-runtime--org.antlr__antlr4-runtime__4.8-1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.antlr--stringtemplate--org.antlr__stringtemplate__3.2.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.ant--ant--org.apache.ant__ant__1.9.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.ant--ant-jsch--org.apache.ant__ant-jsch__1.9.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.ant--ant-launcher--org.apache.ant__ant-launcher__1.9.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.arrow--arrow-format--org.apache.arrow__arrow-format__2.0.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.arrow--arrow-memory-core--org.apache.arrow__arrow-memory-core__2.0.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.arrow--arrow-memory-netty--org.apache.arrow__arrow-memory-netty__2.0.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.arrow--arrow-vector--org.apache.arrow__arrow-vector__2.0.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.avro--avro--org.apache.avro__avro__1.8.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.avro--avro-ipc--org.apache.avro__avro-ipc__1.8.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.avro--avro-mapred-hadoop2--org.apache.avro__avro-mapred-hadoop2__1.8.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.commons--commons-compress--org.apache.commons__commons-compress__1.20.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.commons--commons-crypto--org.apache.commons__commons-crypto__1.1.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.commons--commons-lang3--org.apache.commons__commons-lang3__3.10.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.commons--commons-math3--org.apache.commons__commons-math3__3.4.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.commons--commons-text--org.apache.commons__commons-text__1.6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.curator--curator-client--org.apache.curator__curator-client__2.7.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.curator--curator-framework--org.apache.curator__curator-framework__2.7.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.curator--curator-recipes--org.apache.curator__curator-recipes__2.7.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.derby--derby--org.apache.derby__derby__10.12.1.1.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.directory.api--api-asn1-api--org.apache.directory.api__api-asn1-api__1.0.0-M20.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.directory.api--api-util--org.apache.directory.api__api-util__1.0.0-M20.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.directory.server--apacheds-i18n--org.apache.directory.server__apacheds-i18n__2.0.0-M15.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.directory.server--apacheds-kerberos-codec--org.apache.directory.server__apacheds-kerberos-codec__2.0.0-M15.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-annotations--org.apache.hadoop__hadoop-annotations__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-auth--org.apache.hadoop__hadoop-auth__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-client--org.apache.hadoop__hadoop-client__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-common--org.apache.hadoop__hadoop-common__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-hdfs--org.apache.hadoop__hadoop-hdfs__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-mapreduce-client-app--org.apache.hadoop__hadoop-mapreduce-client-app__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-mapreduce-client-common--org.apache.hadoop__hadoop-mapreduce-client-common__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-mapreduce-client-core--org.apache.hadoop__hadoop-mapreduce-client-core__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-mapreduce-client-jobclient--org.apache.hadoop__hadoop-mapreduce-client-jobclient__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-mapreduce-client-shuffle--org.apache.hadoop__hadoop-mapreduce-client-shuffle__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-yarn-api--org.apache.hadoop__hadoop-yarn-api__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-yarn-client--org.apache.hadoop__hadoop-yarn-client__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-yarn-common--org.apache.hadoop__hadoop-yarn-common__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hadoop--hadoop-yarn-server-common--org.apache.hadoop__hadoop-yarn-server-common__2.7.4.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-beeline--org.apache.hive__hive-beeline__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-cli--org.apache.hive__hive-cli__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-common--org.apache.hive__hive-common__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-exec-core--org.apache.hive__hive-exec-core__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-jdbc--org.apache.hive__hive-jdbc__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-llap-client--org.apache.hive__hive-llap-client__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-llap-common--org.apache.hive__hive-llap-common__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-metastore--org.apache.hive__hive-metastore__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-serde--org.apache.hive__hive-serde__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-shims--org.apache.hive__hive-shims__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-storage-api--org.apache.hive__hive-storage-api__2.7.2.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive--hive-vector-code-gen--org.apache.hive__hive-vector-code-gen__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive.shims--hive-shims-0.23--org.apache.hive.shims__hive-shims-0.23__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive.shims--hive-shims-common--org.apache.hive.shims__hive-shims-common__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.hive.shims--hive-shims-scheduler--org.apache.hive.shims__hive-shims-scheduler__2.3.7.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.htrace--htrace-core--org.apache.htrace__htrace-core__3.1.0-incubating.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.httpcomponents--httpclient--org.apache.httpcomponents__httpclient__4.5.6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.httpcomponents--httpcore--org.apache.httpcomponents__httpcore__4.4.12.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.ivy--ivy--org.apache.ivy__ivy__2.4.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.mesos--mesos-shaded-protobuf--org.apache.mesos__mesos-shaded-protobuf__1.4.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.orc--orc-core--org.apache.orc__orc-core__1.5.12.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.orc--orc-mapreduce--org.apache.orc__orc-mapreduce__1.5.12.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.orc--orc-shims--org.apache.orc__orc-shims__1.5.12.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.parquet--parquet-column--org.apache.parquet__parquet-column__1.10.1-databricks6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.parquet--parquet-common--org.apache.parquet__parquet-common__1.10.1-databricks6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.parquet--parquet-encoding--org.apache.parquet__parquet-encoding__1.10.1-databricks6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.parquet--parquet-format--org.apache.parquet__parquet-format__2.4.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.parquet--parquet-hadoop--org.apache.parquet__parquet-hadoop__1.10.1-databricks6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.parquet--parquet-jackson--org.apache.parquet__parquet-jackson__1.10.1-databricks6.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.thrift--libfb303--org.apache.thrift__libfb303__0.9.3.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.thrift--libthrift--org.apache.thrift__libthrift__0.12.0.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.velocity--velocity--org.apache.velocity__velocity__1.5.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.apache.xbean--xbean-asm7-shaded--org.apache.xbean__xbean-asm7-shaded__4.15.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.codehaus.jackson--jackson-core-asl--org.codehaus.jackson__jackson-core-asl__1.9.13.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.codehaus.jackson--jackson-jaxrs--org.codehaus.jackson__jackson-jaxrs__1.9.13.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.codehaus.jackson--jackson-mapper-asl--org.codehaus.jackson__jackson-mapper-asl__1.9.13.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.codehaus.jackson--jackson-xc--org.codehaus.jackson__jackson-xc__1.9.13.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.codehaus.janino--commons-compiler--org.codehaus.janino__commons-compiler__3.0.16.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.codehaus.janino--janino--org.codehaus.janino__janino__3.0.16.jar:/databricks/jars/----workspace_spark_3_1--maven-trees--hive-2.3__hadoop-2.7--org.datanucleus--datanucleus-api-jdo--org.datanucle\n*** WARNING: skipped 48806 bytes of output ***\n\n (&#39;spark.sql.hive.metastore.sharedPrefixes&#39;,\n  &#39;org.mariadb.jdbc,com.mysql.jdbc,org.postgresql,com.microsoft.sqlserver,microsoft.sql.DateTimeOffset,microsoft.sql.Types,com.databricks,com.codahale,com.fasterxml.jackson,shaded.databricks&#39;),\n (&#39;spark.databricks.io.directoryCommit.enableLogicalDelete&#39;, &#39;false&#39;),\n (&#39;spark.task.reaper.killTimeout&#39;, &#39;60s&#39;),\n (&#39;spark.r.numRBackendThreads&#39;, &#39;1&#39;),\n (&#39;spark.hadoop.fs.wasbs.impl.disable.cache&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.parquet.block.size.row.check.min&#39;, &#39;10&#39;),\n (&#39;spark.hadoop.hive.server2.use.SSL&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.fs.abfss.impl.disable.cache&#39;, &#39;true&#39;),\n (&#39;spark.databricks.workspace.multipleResults.enabled&#39;, &#39;true&#39;),\n (&#39;spark.sql.hive.metastore.version&#39;, &#39;0.13.0&#39;),\n (&#39;spark.shuffle.service.port&#39;, &#39;4048&#39;),\n (&#39;spark.databricks.clusterUsageTags.instanceWorkerEnvNetworkType&#39;, &#39;default&#39;),\n (&#39;spark.databricks.acl.client&#39;,\n  &#39;com.databricks.spark.sql.acl.client.SparkSqlAclClient&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterAvailability&#39;, &#39;ON_DEMAND&#39;),\n (&#39;spark.hadoop.hive.warehouse.subdir.inherit.perms&#39;, &#39;false&#39;),\n (&#39;spark.streaming.driver.writeAheadLog.closeFileAfterWrite&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterUsageTags.userProvidedRemoteVolumeSizeGb&#39;, &#39;0&#39;),\n (&#39;spark.hadoop.hive.server2.keystore.path&#39;,\n  &#39;/databricks/keys/jetty-ssl-driver-keystore.jks&#39;),\n (&#39;spark.databricks.clusterUsageTags.containerZoneId&#39;, &#39;us-west-2b&#39;),\n (&#39;spark.databricks.credential.redactor&#39;,\n  &#39;com.databricks.logging.secrets.CredentialRedactorProxyImpl&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterPinned&#39;, &#39;false&#39;),\n (&#39;spark.databricks.acl.provider&#39;,\n  &#39;com.databricks.sql.acl.ReflectionBackedAclProvider&#39;),\n (&#39;spark.hadoop.fs.s3n.impl&#39;,\n  &#39;shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystem&#39;),\n (&#39;spark.extraListeners&#39;,\n  &#39;com.databricks.backend.daemon.driver.DBCEventLoggingListener&#39;),\n (&#39;spark.databricks.clusterUsageTags.enableElasticDisk&#39;, &#39;false&#39;),\n (&#39;spark.hadoop.spark.databricks.io.parquet.verifyChecksumOnWrite.enabled&#39;,\n  &#39;false&#39;),\n (&#39;spark.sql.parquet.cacheMetadata&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterUsageTags.numPerGlobalInitScriptsV2&#39;, &#39;0&#39;),\n (&#39;spark.hadoop.fs.adl.impl&#39;, &#39;com.databricks.adl.AdlFileSystem&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterNodeType&#39;, &#39;dev-tier-node&#39;),\n (&#39;spark.hadoop.fs.cpfs-abfss.impl.disable.cache&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterUsageTags.enableLocalDiskEncryption&#39;, &#39;false&#39;),\n (&#39;spark.databricks.tahoe.logStore.class&#39;,\n  &#39;com.databricks.tahoe.store.DelegatingLogStore&#39;),\n (&#39;libraryDownload.sleepIntervalSeconds&#39;, &#39;5&#39;),\n (&#39;spark.databricks.cloudProvider&#39;, &#39;AWS&#39;),\n (&#39;spark.sql.hive.convertMetastoreParquet&#39;, &#39;true&#39;),\n (&#39;spark.executor.id&#39;, &#39;driver&#39;),\n (&#39;spark.databricks.passthrough.adls.tokenProviderClassName&#39;,\n  &#39;com.databricks.backend.daemon.data.client.adl.AdlCredentialContextTokenProvider&#39;),\n (&#39;spark.app.name&#39;, &#39;Databricks Shell&#39;),\n (&#39;spark.driver.allowMultipleContexts&#39;, &#39;false&#39;),\n (&#39;spark.databricks.clusterUsageTags.workerEnvironmentId&#39;,\n  &#39;default-worker-env&#39;),\n (&#39;spark.databricks.service.dbutils.server.backend&#39;,\n  &#39;com.databricks.dbconnect.SparkServerDBUtils&#39;),\n (&#39;spark.rdd.compress&#39;, &#39;true&#39;),\n (&#39;spark.databricks.repl.enableClassFileCleanup&#39;, &#39;true&#39;),\n (&#39;spark.databricks.eventLog.dir&#39;, &#39;eventlogs&#39;),\n (&#39;spark.databricks.driverNfs.pathSuffix&#39;, &#39;.ephemeral_nfs&#39;),\n (&#39;spark.sql.catalogImplementation&#39;, &#39;hive&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterCreator&#39;, &#39;Webapp&#39;),\n (&#39;spark.speculation&#39;, &#39;false&#39;),\n (&#39;spark.hadoop.fs.s3a.multipart.size&#39;, &#39;10485760&#39;),\n (&#39;spark.databricks.clusterUsageTags.cloudProvider&#39;, &#39;AWS&#39;),\n (&#39;spark.hadoop.databricks.dbfs.client.version&#39;, &#39;v1&#39;),\n (&#39;spark.hadoop.hive.server2.session.check.interval&#39;, &#39;60000&#39;),\n (&#39;spark.sql.hive.convertCTAS&#39;, &#39;true&#39;),\n (&#39;spark.metrics.conf&#39;, &#39;/databricks/spark/conf/metrics.properties&#39;),\n (&#39;spark.hadoop.spark.sql.parquet.output.committer.class&#39;,\n  &#39;org.apache.spark.sql.parquet.DirectParquetOutputCommitter&#39;),\n (&#39;spark.app.startTime&#39;, &#39;1623505979955&#39;),\n (&#39;spark.hadoop.fs.gs.impl&#39;,\n  &#39;shaded.databricks.V2_1_4.com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem&#39;),\n (&#39;spark.hadoop.fs.s3a.fast.upload.default&#39;, &#39;true&#39;),\n (&#39;spark.akka.frameSize&#39;, &#39;256&#39;),\n (&#39;spark.hadoop.fs.s3a.fast.upload&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterGeneration&#39;, &#39;0&#39;),\n (&#39;spark.hadoop.fs.abfs.impl.disable.cache&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.fs.wasbs.impl&#39;,\n  &#39;shaded.databricks.org.apache.hadoop.fs.azure.NativeAzureFileSystem&#39;),\n (&#39;spark.sql.streaming.stopTimeout&#39;, &#39;15s&#39;),\n (&#39;spark.hadoop.hive.server2.keystore.password&#39;, &#39;[REDACTED]&#39;),\n (&#39;spark.speculation.multiplier&#39;, &#39;3&#39;),\n (&#39;spark.storage.blockManagerTimeoutIntervalMs&#39;, &#39;300000&#39;),\n (&#39;spark.databricks.overrideDefaultCommitProtocol&#39;,\n  &#39;org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterOwnerOrgId&#39;, &#39;4173788838256447&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterNoDriverDaemon&#39;, &#39;false&#39;),\n (&#39;spark.databricks.clusterUsageTags.instanceWorkerEnvId&#39;,\n  &#39;default-worker-env&#39;),\n (&#39;libraryDownload.timeoutSeconds&#39;, &#39;180&#39;),\n (&#39;spark.hadoop.parquet.memory.pool.ratio&#39;, &#39;0.5&#39;),\n (&#39;spark.sparkr.use.daemon&#39;, &#39;false&#39;),\n (&#39;spark.scheduler.listenerbus.eventqueue.capacity&#39;, &#39;20000&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterScalingType&#39;, &#39;fixed_size&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterStateMessage&#39;, &#39;Starting Spark&#39;),\n (&#39;spark.sql.hive.metastore.jars&#39;, &#39;/databricks/hive/*&#39;),\n (&#39;spark.databricks.passthrough.adls.gen2.tokenProviderClassName&#39;,\n  &#39;com.databricks.backend.daemon.data.client.adl.AdlGen2CredentialContextTokenProvider&#39;),\n (&#39;spark.hadoop.parquet.page.write-checksum.enabled&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.databricks.s3commit.client.sslTrustAll&#39;, &#39;false&#39;),\n (&#39;spark.hadoop.fs.s3a.threads.max&#39;, &#39;136&#39;),\n (&#39;spark.r.backendConnectionTimeout&#39;, &#39;604800&#39;),\n (&#39;spark.databricks.tahoe.logStore.gcp.class&#39;,\n  &#39;com.databricks.tahoe.store.GCPLogStore&#39;),\n (&#39;spark.serializer.objectStreamReset&#39;, &#39;100&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterOwnerUserId&#39;, &#39;8377913310544237&#39;),\n (&#39;spark.sql.sources.commitProtocolClass&#39;,\n  &#39;com.databricks.sql.transaction.directory.DirectoryAtomicCommitProtocol&#39;),\n (&#39;spark.hadoop.fs.abfss.impl&#39;,\n  &#39;shaded.databricks.azurebfs.org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem&#39;),\n (&#39;spark.hadoop.hive.server2.idle.session.timeout&#39;, &#39;900000&#39;),\n (&#39;spark.databricks.redactor&#39;,\n  &#39;com.databricks.spark.util.DatabricksSparkLogRedactorProxy&#39;),\n (&#39;spark.databricks.clusterUsageTags.autoTerminationMinutes&#39;, &#39;120&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterPythonVersion&#39;, &#39;3&#39;),\n (&#39;spark.hadoop.fs.s3a.impl&#39;,\n  &#39;shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystem&#39;),\n (&#39;spark.databricks.clusterUsageTags.enableDfAcls&#39;, &#39;false&#39;),\n (&#39;spark.databricks.clusterUsageTags.userProvidedRemoteVolumeCount&#39;, &#39;0&#39;),\n (&#39;spark.shuffle.service.enabled&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.fs.cpfs-s3.impl&#39;,\n  &#39;com.databricks.sql.acl.fs.CredentialPassthroughFileSystem&#39;),\n (&#39;spark.hadoop.parquet.page.verify-checksum.enabled&#39;, &#39;true&#39;),\n (&#39;spark.hadoop.fs.s3a.multipart.threshold&#39;, &#39;104857600&#39;),\n (&#39;spark.databricks.clusterUsageTags.dataPlaneRegion&#39;, &#39;us-west-2&#39;),\n (&#39;spark.rpc.message.maxSize&#39;, &#39;256&#39;),\n (&#39;spark.logConf&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterUsageTags.enableJobsAutostart&#39;, &#39;true&#39;),\n (&#39;spark.databricks.driverNfs.enabled&#39;, &#39;true&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterMetastoreAccessType&#39;,\n  &#39;RDS_DIRECT&#39;),\n (&#39;spark.hadoop.hive.server2.enable.doAs&#39;, &#39;false&#39;),\n (&#39;eventLog.rolloverIntervalSeconds&#39;, &#39;3600&#39;),\n (&#39;spark.databricks.clusterUsageTags.ngrokNpipEnabled&#39;, &#39;false&#39;),\n (&#39;spark.databricks.clusterUsageTags.instanceProfileUsed&#39;, &#39;false&#39;),\n (&#39;spark.shuffle.memoryFraction&#39;, &#39;0.2&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterAllTags&#39;,\n  &#39;[{&#34;key&#34;:&#34;Name&#34;,&#34;value&#34;:&#34;ce-worker&#34;}]&#39;),\n (&#39;spark.databricks.clusterUsageTags.driverInstanceId&#39;, &#39;i-063aee2d40ca68cb6&#39;),\n (&#39;spark.hadoop.fs.abfs.impl&#39;,\n  &#39;shaded.databricks.azurebfs.org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem&#39;),\n (&#39;spark.hadoop.fs.cpfs-s3a.impl&#39;,\n  &#39;com.databricks.sql.acl.fs.CredentialPassthroughFileSystem&#39;),\n (&#39;spark.r.sql.derby.temp.dir&#39;, &#39;/tmp/RtmpgbfILv&#39;),\n (&#39;spark.databricks.acl.scim.client&#39;,\n  &#39;com.databricks.spark.sql.acl.client.DriverToWebappScimClient&#39;),\n (&#39;spark.databricks.clusterUsageTags.region&#39;, &#39;us-west-2&#39;),\n (&#39;spark.databricks.clusterUsageTags.clusterSpotBidPricePercent&#39;, &#39;100&#39;)]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.sparkContext._conf.get('spark.executor.memory')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e64a26ff-8a45-48ed-8315-61137a8eae8c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[6]: &#39;8278m&#39;</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[6]: &#39;8278m&#39;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.sparkContext._conf.get('spark.driver.maxResultSize')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cd1d85ab-cc18-4dab-8528-d23efda736a3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[19]: &#39;4g&#39;</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[19]: &#39;4g&#39;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.sparkContext._conf.get('spark.executor.cores')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b0677c46-f2b3-48e2-beb2-26c37ec8e615"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.sparkContext._conf.get('spark.executor.instances')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7dc61e97-0e9d-4750-b01a-138718e8abe2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.sparkContext._conf.get('spark.sql.autoBroadcastJoinThreshold')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"391abaac-27ab-4c90-836a-36e7277a3e4b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.sparkContext._conf.get('spark.sql.shuffle.partitions')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a1189471-0109-43d2-b274-f62c212ec515"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.sparkContext._conf.get('spark.sql.files.maxPartitionBytes') "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca981c75-2edb-4bad-bbcc-4dcd00b03d38"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bee2075e-84d2-452b-a892-84162434e160"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"12 Spark Configuration","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3727366840950845}},"nbformat":4,"nbformat_minor":0}
